import streamlit as st
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold
import fitz  # PyMuPDF
import docx
import io
import json
import re
import os
import gc
import time
from PIL import Image
from difflib import SequenceMatcher

# ----------------- CONFIGURAÃ‡ÃƒO DA PÃGINA -----------------
st.set_page_config(
    page_title="Validador Auto-Select",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ----------------- ESTILOS CSS -----------------
st.markdown("""
<style>
    header[data-testid="stHeader"] { display: none !important; }
    .main .block-container { padding-top: 20px !important; }
    .main { background-color: #f4f6f8; }
    h1, h2, h3 { color: #2c3e50; font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; }
    
    .stCard {
        background-color: white; padding: 25px; border-radius: 15px;
        box-shadow: 0 10px 20px rgba(0,0,0,0.05); margin-bottom: 25px;
        border: 1px solid #e1e4e8; 
    }
    
    mark.diff { background-color: #fff3cd; color: #856404; padding: 2px 4px; border-radius: 3px; font-weight: 500; }
    mark.ort { background-color: #ffcccc; color: #cc0000; padding: 2px 4px; border-radius: 3px; font-weight: bold; }
    mark.anvisa { background-color: #cce5ff; color: #004085; padding: 2px 4px; border-radius: 3px; font-weight: bold; }
    
    .stButton>button { width: 100%; background-color: #55a68e; color: white; font-weight: bold; border-radius: 10px; height: 55px; border: none; font-size: 16px; }
    .stButton>button:hover { background-color: #448c75; }

    section[data-testid="stSidebar"] { background-color: #ffffff; border-right: 1px solid #eee; }
</style>
""", unsafe_allow_html=True)

# ----------------- CONSTANTES -----------------
SECOES_PACIENTE = [
    "APRESENTAÃ‡Ã•ES", "COMPOSIÃ‡ÃƒO", 
    "PARA QUE ESTE MEDICAMENTO Ã‰ INDICADO", "COMO ESTE MEDICAMENTO FUNCIONA?", 
    "QUANDO NÃƒO DEVO USAR ESTE MEDICAMENTO?", "O QUE DEVO SABER ANTES DE USAR ESTE MEDICAMENTO?", 
    "ONDE, COMO E POR QUANTO TEMPO POSSO GUARDAR ESTE MEDICAMENTO?", "COMO DEVO USAR ESTE MEDICAMENTO?", 
    "O QUE DEVO FAZER QUANDO EU ME ESQUECER DE USAR ESTE MEDICAMENTO?", 
    "QUAIS OS MALES QUE ESTE MEDICAMENTO PODE CAUSAR?", 
    "O QUE FAZER SE ALGUEM USAR UMA QUANTIDADE MAIOR DO QUE A INDICADA DESTE MEDICAMENTO?", 
    "DIZERES LEGAIS"
]

SECOES_PROFISSIONAL = [
    "APRESENTAÃ‡Ã•ES", "COMPOSIÃ‡ÃƒO", "INDICAÃ‡Ã•ES", "RESULTADOS DE EFICÃCIA", 
    "CARACTERÃSTICAS FARMACOLÃ“GICAS", "CONTRAINDICAÃ‡Ã•ES", "ADVERTÃŠNCIAS E PRECAUÃ‡Ã•ES", 
    "INTERAÃ‡Ã•ES MEDICAMENTOSAS", "CUIDADOS DE ARMAZENAMENTO DO MEDICAMENTO", 
    "POSOLOGIA E MODO DE USAR", "REAÃ‡Ã•ES ADVERSAS", "SUPERDOSE", "DIZERES LEGAIS"
]

SAFETY_SETTINGS = {
    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
}

# ----------------- FUNÃ‡Ã•ES DE BACKEND -----------------

def configure_gemini():
    api_key = None
    try: 
        api_key = st.secrets["GEMINI_API_KEY"]
    except: 
        api_key = os.environ.get("GEMINI_API_KEY")
    
    if not api_key: 
        return False
    
    genai.configure(api_key=api_key)
    return True

def auto_select_best_model():
    """
    VERSÃƒO OTIMIZADA PARA COTA: Prioriza modelos leves e faz pausas para evitar bloqueio.
    """
    try:
        all_models = list(genai.list_models())
        candidates = []
        
        # Filtra modelos que suportam generateContent
        for m in all_models:
            if 'generateContent' in m.supported_generation_methods:
                candidates.append(m.name)
        
        if not candidates:
            st.error("âŒ Nenhum modelo encontrado na API")
            return None
        
        st.info(f"ğŸ” Encontrados {len(candidates)} modelos. Testando os mais estÃ¡veis primeiro...")
        
        # Sistema de prioridade FOCADO EM ESTABILIDADE E COTA
        def priority_score(name):
            score = 0
            name_lower = name.lower()
            
            # Prioriza modelos "Flash" e "Lite" (Maior Cota)
            if "gemini-1.5-flash" in name_lower and "8b" not in name_lower: score += 200 # O mais estÃ¡vel de todos
            if "gemini-2.0-flash-lite" in name_lower: score += 190
            if "gemini-1.5-flash-8b" in name_lower: score += 180
            if "gemini-2.0-flash" in name_lower and "lite" not in name_lower: score += 150
            
            # Modelos Pro/Exp (Cota menor, deixa pro final)
            if "gemini-1.5-pro" in name_lower: score += 100
            if "exp" in name_lower: score += 50 # Experimental cai muito a cota
            
            # Penaliza modelos problemÃ¡ticos para essa tarefa
            if "thinking" in name_lower: score -= 500
            if "vision" in name_lower: score -= 100
            if "image" in name_lower: score -= 100
            if "robotics" in name_lower: score -= 1000
            if "tts" in name_lower: score -= 1000
            if "gemma" in name_lower: score -= 2000 # Gemma nÃ£o lÃª imagens (erro 400)
            
            return score
        
        candidates.sort(key=priority_score, reverse=True)
        
        # Mostra os top 5 candidatos
        with st.expander("ğŸ“‹ Top 5 Modelos PrioritÃ¡rios"):
            for i, model_name in enumerate(candidates[:5], 1):
                st.caption(f"{i}. {model_name}")
        
        test_prompt = 'Responda em JSON: {"status": "ok"}'
        
        tested_count = 0
        failed_quota = []
        
        # TESTA COM PAUSA DE SEGURANÃ‡A
        for model_name in candidates:
            tested_count += 1
            
            # Pula modelos obviamente ruins baseados no nome
            if "robotics" in model_name or "tts" in model_name or "gemma" in model_name:
                continue

            try:
                st.caption(f"ğŸ§ª Testando [{tested_count}]: {model_name}")
                
                model = genai.GenerativeModel(model_name)
                
                response = model.generate_content(
                    test_prompt,
                    generation_config={"max_output_tokens": 50, "temperature": 0.0},
                    safety_settings=SAFETY_SETTINGS,
                    request_options={"timeout": 15}
                )
                
                if response and hasattr(response, 'text'):
                     st.success(f"âœ… ENCONTRADO! Modelo funcional: {model_name}")
                     return model_name
                    
            except Exception as e:
                error_msg = str(e).lower()
                if "429" in error_msg or "quota" in error_msg or "resource_exhausted" in error_msg:
                    failed_quota.append(model_name)
                    st.warning(f"â­ï¸ Cota cheia: {model_name}")
                    time.sleep(1.0) # PAUSA IMPORTANTE: Espera 1s para recuperar fÃ´lego da API
                else:
                    st.caption(f"âš ï¸ Erro: {model_name} ({str(e)[:50]})")
                
                continue
        
        # Se todos falharem por cota, tenta o 1.5 Flash na marra (costuma voltar rÃ¡pido)
        st.error(f"âŒ Todos os {tested_count} modelos falharam.")
        st.warning("âš ï¸ ForÃ§ando uso do 'gemini-1.5-flash' (Ã© o que recupera mais rÃ¡pido)")
        return "models/gemini-1.5-flash"
        
    except Exception as e:
        st.error(f"âŒ Erro fatal: {e}")
        return "models/gemini-1.5-flash"

def process_uploaded_file(uploaded_file):
    if not uploaded_file: 
        return None
    
    try:
        file_bytes = uploaded_file.read()
        filename = uploaded_file.name.lower()
        
        if filename.endswith('.docx'):
            doc = docx.Document(io.BytesIO(file_bytes))
            text = "\n".join([p.text for p in doc.paragraphs])
            return {"type": "text", "data": text}
            
        elif filename.endswith('.pdf'):
            doc = fitz.open(stream=file_bytes, filetype="pdf")
            full_text = ""
            for page in doc: 
                full_text += page.get_text() + "\n"
            
            # Se tem muito texto, usa modo texto
            if len(full_text.strip()) > 800:
                doc.close()
                return {"type": "text", "data": full_text}
            
            # Caso contrÃ¡rio, extrai imagens
            images = []
            limit = min(15, len(doc))
            for i in range(limit):
                pix = doc[i].get_pixmap(matrix=fitz.Matrix(2.5, 2.5), dpi=200)
                try: 
                    img_byte_arr = io.BytesIO(pix.tobytes("jpeg", jpg_quality=95))
                except: 
                    img_byte_arr = io.BytesIO(pix.tobytes("png"))
                images.append(Image.open(img_byte_arr))
            
            doc.close()
            gc.collect()
            return {"type": "images", "data": images}
            
    except Exception as e:
        st.error(f"Erro ao processar arquivo: {e}")
        return None
    
    return None

def clean_json_response(text):
    text = text.replace("```json", "").replace("```", "").strip()
    return re.sub(r'//.*', '', text)

def extract_json(text):
    cleaned = clean_json_response(text)
    try: 
        return json.loads(cleaned, strict=False)
    except: 
        pass
    try:
        if '"SECOES":' in cleaned:
            last_bracket = cleaned.rfind("}")
            if last_bracket != -1:
                fixed = cleaned[:last_bracket+1]
                if not fixed.strip().endswith("]}"): 
                    if fixed.strip().endswith("]"): fixed += "}"
                    else: fixed += "]}"
                return json.loads(fixed, strict=False)
    except: 
        pass
    return None

def normalize_sections(data_json, allowed_titles):
    if not data_json or "SECOES" not in data_json: 
        return data_json
    clean = []
    def normalize(t): return re.sub(r'[^A-ZÃƒÃ•ÃÃ‰ÃÃ“ÃšÃ‡]', '', t.upper())
    allowed_norm = {normalize(t): t for t in allowed_titles}
    for sec in data_json["SECOES"]:
        raw_title = sec.get("titulo", "")
        t_ia = normalize(raw_title)
        match = allowed_norm.get(t_ia)
        if not match:
            for k, v in allowed_norm.items():
                if k in t_ia or t_ia in k or SequenceMatcher(None, k, t_ia).ratio() > 0.8:
                    match = v
                    break
        if match:
            sec["titulo"] = match
            clean.append(sec)
    data_json["SECOES"] = clean
    return data_json

# ----------------- UI LATERAL -----------------
with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/3004/3004458.png", width=80)
    st.markdown("<h2 style='text-align: center; color: #55a68e;'>Validador Auto</h2>", unsafe_allow_html=True)
    pagina = st.radio("NavegaÃ§Ã£o:", ["ğŸ  InÃ­cio", "ğŸ’Š Ref x BELFAR", "ğŸ“‹ ConferÃªncia MKT", "ğŸ¨ GrÃ¡fica x Arte"], label_visibility="collapsed")
    st.divider()
    is_connected = configure_gemini()
    if is_connected:
        st.success("âœ… Conectado Ã  API")
    else:
        st.error("âŒ API Key nÃ£o encontrada")

# ----------------- LÃ“GICA PRINCIPAL -----------------
if pagina == "ğŸ  InÃ­cio":
    st.markdown("<h1 style='color:#55a68e;text-align:center;'>Validador Inteligente</h1>", unsafe_allow_html=True)
    st.info("ğŸ’¡ Este sistema testa os modelos disponÃ­veis priorizando os mais estÃ¡veis (Flash).")
    c1, c2, c3 = st.columns(3)
    c1.info("ğŸ’Š Ref x BELFAR")
    c2.info("ğŸ“‹ Conf. MKT")
    c3.info("ğŸ¨ GrÃ¡fica")

else:
    st.markdown(f"## {pagina}")
    lista_secoes = SECOES_PACIENTE
    if pagina == "ğŸ’Š Ref x BELFAR":
        tipo_bula = st.radio("Tipo de Bula:", ["Paciente", "Profissional"], horizontal=True)
        if tipo_bula == "Profissional":
            lista_secoes = SECOES_PROFISSIONAL
            
    c1, c2 = st.columns(2)
    f1 = c1.file_uploader("ğŸ“„ Arquivo ReferÃªncia", type=["pdf", "docx"], key="f1")
    f2 = c2.file_uploader("ğŸ“‹ Arquivo Candidato", type=["pdf", "docx"], key="f2")
        
    if st.button("ğŸš€ INICIAR AUDITORIA"):
        if not f1 or not f2:
            st.error("âŒ Por favor, envie os dois arquivos")
        elif not is_connected:
            st.error("âŒ API nÃ£o configurada.")
        else:
            with st.spinner("ğŸ” Buscando modelo com cota disponÃ­vel..."):
                best_model = auto_select_best_model()
            
            st.success(f"âœ… IA Selecionada: **{best_model}**", icon="ğŸ¤–")
            time.sleep(0.5)
            
            with st.spinner("ğŸ“– Processando arquivos..."):
                d1 = process_uploaded_file(f1)
                d2 = process_uploaded_file(f2)
                gc.collect()

            if not d1 or not d2:
                st.error("âŒ Erro ao processar um dos arquivos")
            else:
                model = genai.GenerativeModel(best_model)
                final_sections = []
                final_dates = []
                success = False
                
                payload = ["ğŸ”¬ AUDITORIA FARMACÃŠUTICA COMPLETA"]
                if d1['type'] == 'text': payload.append(f"ğŸ“„ REFERÃŠNCIA (TEXTO):\n{d1['data']}")
                else: payload.extend(["ğŸ“„ REFERÃŠNCIA (IMAGENS):"] + d1['data'])
                if d2['type'] == 'text': payload.append(f"ğŸ“‹ CANDIDATO (TEXTO):\n{d2['data']}")
                else: payload.extend(["ğŸ“‹ CANDIDATO (IMAGENS):"] + d2['data'])

                secoes_str = "\n".join([f"   {i+1}. {s}" for i, s in enumerate(lista_secoes)])
                prompt = f"""
ğŸ¯ MISSÃƒO CRÃTICA: Auditor FarmacÃªutico de MÃ¡xima PrecisÃ£o
ğŸ“‹ SEÃ‡Ã•ES OBRIGATÃ“RIAS (EXTRAIR TODAS COMPLETAMENTE):
{secoes_str}
ğŸ”´ REGRAS ABSOLUTAS:
1ï¸âƒ£ EXTRAÃ‡ÃƒO 100% COMPLETA (Copie TODO o texto).
2ï¸âƒ£ COMPARAÃ‡ÃƒO PALAVRA POR PALAVRA (Identifique diferenÃ§as).
3ï¸âƒ£ MARCAÃ‡Ã•ES: <mark class='diff'>DIVERGÃŠNCIA</mark>, <mark class='ort'>ERRO ORTOGRÃFICO</mark>, <mark class='anvisa'>DATA</mark>.
ğŸ“¤ FORMATO JSON: {{ "METADADOS": {{ "datas": [] }}, "SECOES": [ {{ "titulo": "...", "ref": "...", "bel": "...", "status": "..." }} ] }}
"""
                try:
                    with st.spinner(f"ğŸ” Auditando com {best_model}..."):
                        response = model.generate_content(
                            [prompt] + payload,
                            generation_config={"response_mime_type": "application/json", "max_output_tokens": 20000, "temperature": 0.0},
                            safety_settings=SAFETY_SETTINGS,
                            request_options={"timeout": 1200}
                        )
                        data = extract_json(response.text)
                        if data and "SECOES" in data:
                            norm = normalize_sections(data, lista_secoes)
                            final_sections = norm.get("SECOES", [])
                            final_dates = data.get("METADADOS", {}).get("datas", [])
                            success = True
                except Exception as e:
                    st.error(f"âŒ Erro na auditoria: {str(e)}")

                if success and final_sections:
                    st.success(f"âœ… Auditoria Completa!")
                    st.divider()
                    secs = final_sections
                    cM1, cM2, cM3 = st.columns(3)
                    divs = sum(1 for s in secs if "DIVERGENTE" in s.get('status', 'OK') or "ERRO" in s.get('status', 'OK'))
                    score = 100 - int((divs/max(1, len(secs)))*100) if len(secs) > 0 else 0
                    cM1.metric("Score", f"{score}%")
                    cM2.metric("SeÃ§Ãµes", f"{len(secs)}/{len(lista_secoes)}")
                    cM3.markdown(f"**Data Anvisa**<br><mark class='anvisa'>{final_dates[0] if final_dates else 'N/A'}</mark>", unsafe_allow_html=True)
                    st.markdown("---")
                    for sec in secs:
                        status = sec.get('status', 'OK')
                        icon = "âœ…"
                        if "DIVERGENTE" in status or "ERRO" in status: icon = "âŒ"
                        elif "FALTANTE" in status: icon = "ğŸš¨"
                        with st.expander(f"{icon} {sec['titulo']} - {status}"):
                            cA, cB = st.columns(2)
                            cA.markdown(f"**ReferÃªncia**\n<div style='background:#f8f9fa;padding:15px;font-size:0.9em;white-space:pre-wrap;'>{sec.get('ref','')}</div>", unsafe_allow_html=True)
                            cB.markdown(f"**Candidato**\n<div style='background:#f1f8e9;padding:15px;font-size:0.9em;white-space:pre-wrap;'>{sec.get('bel','')}</div>", unsafe_allow_html=True)
                            if icon == "âŒ": st.caption("Legenda: ğŸŸ¡ DivergÃªncia | ğŸ”´ Erro PortuguÃªs | ğŸ”µ Data")
                elif success:
                    st.warning("âš ï¸ IA nÃ£o encontrou seÃ§Ãµes.")
                else:
                    st.error("âŒ Falha na auditoria.")
